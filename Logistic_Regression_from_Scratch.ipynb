{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiamMerrill/Logistic_Regression/blob/main/Logistic_Regression_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "4PK4z5ewBOFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load and Inspect Data"
      ],
      "metadata": {
        "id": "INkbJGNGBTAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is collected from uci.edu's [website](https://archive.ics.uci.edu/ml/datasets/banknote+authentication#). \n",
        "\n",
        "Data Set Information:\n",
        "\n",
        "\"Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\"\n",
        "\n",
        "These are the features included in the dataset: \n",
        "\n",
        "1. variance of Wavelet Transformed image (continuous)\n",
        "2. skewness of Wavelet Transformed image (continuous)\n",
        "3. curtosis of Wavelet Transformed image (continuous)\n",
        "4. entropy of image (continuous)\n",
        "5. class (integer)\n",
        "\n"
      ],
      "metadata": {
        "id": "7A_I9NEU4YiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o1Gyqw-z8gn",
        "outputId": "50801783-bb50-41d9-b614-149e8bcd57c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-13 23:39:15--  https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46400 (45K) [application/x-httpd-php]\n",
            "Saving to: ‘data_banknote_authentication.txt’\n",
            "\n",
            "\r          data_bank   0%[                    ]       0  --.-KB/s               \rdata_banknote_authe 100%[===================>]  45.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-11-13 23:39:15 (2.25 MB/s) - ‘data_banknote_authentication.txt’ saved [46400/46400]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('data_banknote_authentication.txt', sep = ',', header=None, \n",
        "                   names=[\"Variance\", \"Skewness\", \"Curtosis\", \"Entropy\", \"Class\"])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QpBckIOr3euJ",
        "outputId": "1b6e64fd-c09a-4909-ed94-8423252622ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Variance  Skewness  Curtosis  Entropy  Class\n",
              "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
              "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
              "2   3.86600   -2.6383    1.9242  0.10645      0\n",
              "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
              "4   0.32924   -4.4552    4.5718 -0.98880      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-153b1c9c-9cb6-4628-9751-1b280a6e669c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variance</th>\n",
              "      <th>Skewness</th>\n",
              "      <th>Curtosis</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.62160</td>\n",
              "      <td>8.6661</td>\n",
              "      <td>-2.8073</td>\n",
              "      <td>-0.44699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.54590</td>\n",
              "      <td>8.1674</td>\n",
              "      <td>-2.4586</td>\n",
              "      <td>-1.46210</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.86600</td>\n",
              "      <td>-2.6383</td>\n",
              "      <td>1.9242</td>\n",
              "      <td>0.10645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.45660</td>\n",
              "      <td>9.5228</td>\n",
              "      <td>-4.0112</td>\n",
              "      <td>-3.59440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.32924</td>\n",
              "      <td>-4.4552</td>\n",
              "      <td>4.5718</td>\n",
              "      <td>-0.98880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-153b1c9c-9cb6-4628-9751-1b280a6e669c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-153b1c9c-9cb6-4628-9751-1b280a6e669c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-153b1c9c-9cb6-4628-9751-1b280a6e669c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classes aren't currently shuffled."
      ],
      "metadata": {
        "id": "VJ-UjAfaTDsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How many entries do we have?\n",
        "print(data.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imx1-jjCFqrg",
        "outputId": "277a83da-7884-4616-90ab-e6797dfe8a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What are class labels? Are they balanced?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(data['Class'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "biiKFh-138KL",
        "outputId": "b4639fb3-a0fd-414d-8806-5912820177ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is slightly skewed but not significantly."
      ],
      "metadata": {
        "id": "1WAXjQFZTMNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "dTnurORdGL2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to split the dataset into training and testing data. Split the dataset into training (80%) and testing data (20%).\n"
      ],
      "metadata": {
        "id": "48PY32elH_4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First I will shuffle the data because it looks like Class is not suffled."
      ],
      "metadata": {
        "id": "-jSxA4-4nqzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac = 1)"
      ],
      "metadata": {
        "id": "hFtOto7ukUQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into 80 percent training and 20 percent testing. I'm doing this using the loc method, grabbing four features in the X variable and Class in the y variable."
      ],
      "metadata": {
        "id": "QFqmequdn1-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#put your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "columns = [\"Variance\", \"Skewness\", \"Curtosis\", \"Entropy\", \"Class\"]\n",
        "data = data.loc[:, columns]\n",
        "features = [\"Variance\", \"Skewness\", \"Curtosis\", \"Entropy\"]\n",
        "X = data.loc[:, features]\n",
        "X['Bias'] = 1\n",
        "y = data.loc[:, ['Class']]\n",
        "#train and test are training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, train_size = .8)"
      ],
      "metadata": {
        "id": "lY7Jjxf7Cgez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "L97BWOzNKF07",
        "outputId": "fa6f26d8-55b5-4b67-d2f5-accff9500ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Class\n",
              "184       0\n",
              "1129      1\n",
              "576       0\n",
              "572       0\n",
              "381       0\n",
              "1355      1\n",
              "196       0\n",
              "1335      1\n",
              "1206      1\n",
              "1269      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c02413d-7842-4e39-b417-958c23754d23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1129</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1355</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c02413d-7842-4e39-b417-958c23754d23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c02413d-7842-4e39-b417-958c23754d23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c02413d-7842-4e39-b417-958c23754d23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data has been shuffled. Checking the size of the train and test size."
      ],
      "metadata": {
        "id": "Aaa_mUTTTVKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train Size: ', X_train.shape[0])\n",
        "print('Test Size: ', X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p94HgqDlJIc4",
        "outputId": "2562a932-896b-4f70-f201-4258f06a4474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Size:  1097\n",
            "Test Size:  275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic regression"
      ],
      "metadata": {
        "id": "EIRGGRT4J5Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression outputs values from zero to one, which we think of as probabilities. Logistic regression is a sigmoid function acting on a linear regression."
      ],
      "metadata": {
        "id": "x5yEFmcy_WVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ltq4adJnxbJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When z is negative, sigmoid is close to zero. When z is positive number, sigmoid is close to 1. "
      ],
      "metadata": {
        "id": "3f2jg-J6x3S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return np.exp(z)/(1 + np.exp(z))"
      ],
      "metadata": {
        "id": "RQyUhP9JVfmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sigmoid(-5))\n",
        "print(sigmoid(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S15uDYNZopTD",
        "outputId": "d9cb59c2-0b2c-4e2e-d749-92ddfe6fc910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.006692850924284856\n",
            "0.9933071490757152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I'm going to impute X into m and n, which makes m the number of rows and n the number of columns.  "
      ],
      "metadata": {
        "id": "k-OtUEHdpZd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m, n = X.shape"
      ],
      "metadata": {
        "id": "UW0XH7usUEV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQKtLwY8pphM",
        "outputId": "92663b5b-574c-49cc-b919-d75aa6726b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I will create a new column and populate it with ones, this will serve as the weights."
      ],
      "metadata": {
        "id": "30GBzkOFp38e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.ones((n,1))"
      ],
      "metadata": {
        "id": "3ArLMlwP-H_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression function takes two arguments, the weights and the data. y_hat, which is our hypothesis, is equal to the dot product of the weights and the data, run through the sigmoid function. The log_res function returns the hypothesis. "
      ],
      "metadata": {
        "id": "U1NW9iHdqDo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_res(w, X):\n",
        "  y_hat = sigmoid(np.dot(w.T, X.T))\n",
        "  return y_hat"
      ],
      "metadata": {
        "id": "yUt-lf_jP_k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_res(w, X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XfCvZqNQHTW",
        "outputId": "41e88385-789b-4dcb-9176-88f9f2f654b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9966072 , 0.03871886, 0.99903075, ..., 0.2199479 , 0.37749367,\n",
              "        0.4182669 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we introduce the maximum likelihood loss function. This takes three arguments, the data, the target and the weights. We first impute the target to m, n. Then define y_n so that y is either -1 or 1. Then we define linear_term to equal the dot product of the weights and the data. Then we define exponent_arg to be equal to -y_n times linear term. Then we take the log of 1 + e to the exponent_arg. Finally, loss is equal to all of that over n. We return loss."
      ],
      "metadata": {
        "id": "nyDE4COfzIpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ml_loss(X, y, w):\n",
        "  \"\"\"Maximum likelihood loss\"\"\"\n",
        "  n, m = y.shape\n",
        "  y_n = np.where(y == 0, -1, 1)\n",
        "  linear_term = np.dot(w.T, X.T)\n",
        "  exponent_arg = np.multiply(-y_n.T, linear_term)\n",
        "  summand = np.log(1 + np.exp(exponent_arg))\n",
        "  loss = np.sum(summand)/n\n",
        "  return loss"
      ],
      "metadata": {
        "id": "26crwN0aWbea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ml_loss(X_train, y_train, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAsaTYlehZnB",
        "outputId": "861a3733-f1e7-4cee-e3c0-090747a63b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.681234767095043"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient descent"
      ],
      "metadata": {
        "id": "4LejnqFK3VDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent finds the lowest loss function in a convex curve. It takes data, the target, and the weights as the argument."
      ],
      "metadata": {
        "id": "v7vTXXdcmMPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_ml_loss(X, y, w):\n",
        "  n, m = y.shape\n",
        "  y_n = np.where(y == 0, -1, 1)\n",
        "  linear_term = np.dot(w.T, X.T)\n",
        "  sig_arg = sigmoid(np.multiply(-y_n.T, linear_term))\n",
        "  left = np.multiply(-1*y_n.T, X.T)\n",
        "  summand = left*sig_arg \n",
        "  grad = 1./n*np.sum(summand, axis=1)\n",
        "  return grad.T"
      ],
      "metadata": {
        "id": "iFH4jd7jiGM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_ml_loss(X_train, y_train, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ1RtD6smR26",
        "outputId": "e4660a43-081a-4183-9fdf-580fad7dbddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.84377087,  2.50125529, -0.10328361, -0.04602236,  0.25234536])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X_train, y_train, lr=0.1, num_epochs=5000):\n",
        "    w = np.random.normal(0, 1.0, size=(5, 1)) #randomly initialized weight vector\n",
        "    for epoch in range(num_epochs):\n",
        "      grad_loss = grad_ml_loss(X_train, y_train, w)\n",
        "      w = w - lr * np.expand_dims(grad_loss, axis=1) \n",
        "      if epoch % 100 == 0:\n",
        "        loss = ml_loss(X_train, y_train, w)\n",
        "        print(f\"Working on epoch: {epoch}\\t Loss: {loss:.4} \\t Weights: {w.T.squeeze()}\", end=\"\\r\")\n",
        "    return w"
      ],
      "metadata": {
        "id": "lqJCtJ-x7hIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X_train, y_train, lr=0.1, num_epochs=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHW6mI8Nebdp",
        "outputId": "fd5ab65e-03ae-45c1-90e8-277d59aa9749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.35300599],\n",
              "       [-1.90894792],\n",
              "       [-2.30214132],\n",
              "       [-0.16998033],\n",
              "       [ 3.43811793]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### logistic regression (with L2 regression)"
      ],
      "metadata": {
        "id": "_wZXjjcX20_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression adds “squared magnitude” of coefficient as penalty term to the loss function. Here we add this as mu.\n"
      ],
      "metadata": {
        "id": "J6nmGLYy0f12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_with_l2(X_train, y_train, lr=0.00000001, mu=0.05, num_epochs=500):\n",
        "    w = np.random.normal(0, 1.0, size=(5, 1))\n",
        "    for epoch in range(num_epochs):\n",
        "      grad_loss = grad_ml_loss(X_train, y_train, w)\n",
        "      w = w - lr * (np.expand_dims(grad_loss, axis=1) + mu*w)\n",
        "      loss = ml_loss(X_train, y_train, w)\n",
        "      if epoch % 100 == 0:\n",
        "        loss = ml_loss(X_train, y_train, w)\n",
        "        print(f\"Epoch: {epoch}\\t Loss: {loss:.4} \\t Weights: {w.T.squeeze()}\", end=\"\\r\")\n",
        "    return w"
      ],
      "metadata": {
        "id": "BUdhvd3B7h5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross entropy error measurement"
      ],
      "metadata": {
        "id": "LwMFW5bX2gC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternative approach would be the cross entropy loss function, below. "
      ],
      "metadata": {
        "id": "DeAqU81FtkcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ce_loss(y, y_hat):\n",
        "    \"\"\"Cross Entropy Loss\"\"\"\n",
        "    loss = -np.mean(y*(np.log(y_hat)) - (1-y)*np.log(1-y_hat))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "kNV9rKpS7ie3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_best = gradient_descent(X_train, y_train, lr=0.1, num_epochs=5000)\n",
        "y_hat = log_res(w_best, X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbqvnfBNr2g4",
        "outputId": "bfabc0ae-93b5-48b8-f207-33242c07c641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ce_loss(y_train, y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rp-AzHHw5m6i",
        "outputId": "0fb75969-aff5-4d79-9e4f-95c812b70828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.7363944444427646"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-fold cross validation"
      ],
      "metadata": {
        "id": "_eQb9-BdLdkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training\n"
      ],
      "metadata": {
        "id": "465EtS9S1BED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses_test = []\n",
        "losses_train = []\n",
        "for i in range(10):\n",
        "  m, n = X.shape\n",
        "  delta = m // 10\n",
        "  X_train = np.concatenate([X[:i*delta].values, X[(i+1)*delta:].values])\n",
        "  X_test = X[i*delta:(i+1)*delta].values\n",
        "  y_train = np.concatenate([y[:i*delta].values, y[(i+1)*delta:].values])\n",
        "  y_test = y[i*delta:(i+1)*delta].values\n",
        "  loss_train = ml_loss(X_train, y_train, w)\n",
        "  loss_test = ml_loss(X_test, y_test, w)\n",
        "  losses_test.append(loss_test)\n",
        "  losses_train.append(loss_train)"
      ],
      "metadata": {
        "id": "-2Eyyhi48kVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sUaYIDWFRMa",
        "outputId": "39e6e0d3-3132-48f3-d761-095fce915b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.6973946966097415,\n",
              " 4.656717130502254,\n",
              " 4.70565169677873,\n",
              " 4.701301798808141,\n",
              " 4.706053948887814,\n",
              " 4.7155802842896755,\n",
              " 4.7051313103238765,\n",
              " 4.7420747208100575,\n",
              " 4.722778216280751,\n",
              " 4.681234767095043]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing\n"
      ],
      "metadata": {
        "id": "I-U0ho3X11UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses_test"
      ],
      "metadata": {
        "id": "Nr6KJGow11UA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5787f00-4fe6-4b1c-fb41-92c80eead9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.758050507016783,\n",
              " 5.124742435066031,\n",
              " 4.683616965347429,\n",
              " 4.722829549242876,\n",
              " 4.679990824072101,\n",
              " 4.594114734865547,\n",
              " 4.688308040323661,\n",
              " 4.355278026086913,\n",
              " 4.529228267646735,\n",
              " 4.903725784028836]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot and Explain"
      ],
      "metadata": {
        "id": "Taf-4K843GpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the $E_{in}$ and $E_{val}$. Then explain your findings"
      ],
      "metadata": {
        "id": "lt2JtT0-3Qt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(losses_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "wCsaRH6cIVvJ",
        "outputId": "5b6a1a08-687c-4a6e-8f33-6d3d1855cac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 0., 1., 0., 1., 4., 1., 1., 0., 1.]),\n",
              " array([4.65671713, 4.66525289, 4.67378865, 4.68232441, 4.69086017,\n",
              "        4.69939593, 4.70793168, 4.71646744, 4.7250032 , 4.73353896,\n",
              "        4.74207472]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(losses_test)"
      ],
      "metadata": {
        "id": "m-Fq6TZp3LBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "5dc6ee51-57dc-4ba1-8ee3-6f6f43da0eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 0., 1., 1., 4., 1., 0., 1., 0., 1.]),\n",
              " array([4.35527803, 4.43222447, 4.50917091, 4.58611735, 4.66306379,\n",
              "        4.74001023, 4.81695667, 4.89390311, 4.97084955, 5.04779599,\n",
              "        5.12474244]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is your analysis? Put them here"
      ],
      "metadata": {
        "id": "8WNOCtYl_yKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Losses for train and test converge around 4.7. In the test set one cycle returned an error over 5, which was not the case in the training data, but as the rest were all close in range this doesn't seem to be an issue. "
      ],
      "metadata": {
        "id": "Ih7IQwHI7Lrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "qAlvHORC5QMq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data set studies bank forgeries, by recording several variables describing the characteristics of bank notes, including Variance, Skewness, Curtosis, and Entropy, and then assigning each bank note a class of 1 or 0, representing a forgery or not a forgery. The goal is to create a logistic regression that will be able to predict whether a future bank note is a forgery or not, by collecting these features and measuring how they compare to the patterns in the dataset. To do this, we create test and training sets of th data. The test set represents 20 percent of th data and th training se trepresents 80 percent of the data. We also separate the data into features and target. \n",
        "\n",
        "Using the sigmoid function, we are able to squish imputs to a number between 1 and 0 on a log scale, using e. This will allow us to make categorical determinations, classifying data as a 1 or 0. \n",
        "\n",
        "The logistic regression produces a hypothesis, by taking the dot product of a set of weights and the data as inputs to the sigmoid function. Improving on this we introduce the maximum likelihood function and gradient descent. These help us to identify the lowest loss function. Adding a coefficient mu as the L2, or ridge regression, stabilizes the results. An alternative approach using cross entropy measurement is provided. \n",
        "\n",
        "In order to ensure that the particular sampe of the data that we are using for training and testing is not skewing the results, we train and test using 10 fold cross validation. This cycles through the data, selecting a different 1/10th of th data for its test set and appending the rest for its training set each time. We output ten counts of loss for each cycle of cross validation. \n",
        "\n",
        "Plotting these in a histogram, we see that most errors are around 4.7 for both training and testing, showing that there is not a meaningful difference between how th model is operating on training data and test data."
      ],
      "metadata": {
        "id": "uRyM2Q-25UN8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uKIo7qy0WQ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}